{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Denoising Autoencoder 代码实现"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Denoising Autoencoder（降噪自动编码器）就是在Autoencoder的基础之上，为了防止过拟合问题而对输入的数据（网络的输入层）加入噪音，使学习得到的编码器W\n",
    "具有较强的鲁棒性，从而增强模型的泛化能力。Denoising Autoencoder是Bengio在08年提出的，具体内容可参考其论文：\n",
    "\n",
    "- Extracting and composing robust features with denoising autoencoders."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 代码实现细节\n",
    "#### 构建一个DAE类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class DenoisingAutoencoder():\n",
    "    def __init__(self, n_input, transfer_fn... ):\n",
    "        ...\n",
    "\n",
    "        # model\n",
    "        self.x = tf.placeholder(dtype=tf.float32, shape=[None, self.n_input])\n",
    "        self.x_corrupted = xxx\n",
    "        self.hidden = self.transfer(tf.add(tf.matmul(self.x_corrupted , self.weights['w1']), self.weights['b1']))\n",
    "        self.reconstruction = tf.add(tf.matmul(self.hidden, self.weights['w2']), self.weights['b2'])\n",
    "\n",
    "        # cost\n",
    "        self.cost = .5*tf.reduce_mean(tf.pow(tf.subtract(self.reconstruction, self.x), 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 三种加噪的方式\n",
    "\n",
    "去噪自编码器模型的输入是原始输入经某种形式的加噪过程后的退化形式，加噪过程一般分为：\n",
    "\n",
    "- 加性高斯噪声（additive gaussian noise）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "self.scale = tf.placeholder(dtype=tf.float32)\n",
    "self.x_corrupted = tf.add(self.x, self.scale * tf.random_normal(shape=(self.n_input, )))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 掩模噪声（mask）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "self.keep_prob = tf.placeholder(dtype=tf.float32)\n",
    "self.x_corrupted = tf.nn.dropout(self.x, self.keep_prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 椒盐噪声"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def salt_and_pepper_noise(X, v):\n",
    "    X_noise = X.copy()\n",
    "    n_features = X.shape[1]\n",
    "    mn = X.min()\n",
    "    mx = X.max()\n",
    "\n",
    "    for i, sample in enumerate(X):\n",
    "        mask = np.random.randint(0, n_features, v)\n",
    "        for m in mask:\n",
    "            if np.random.rand() < .5:\n",
    "                X_noise[i][m] = mn\n",
    "            else:\n",
    "                X_noise[i][m] = mx\n",
    "    return X_noise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 实践代码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Succesfully downloaded', 'train-images-idx3-ubyte.gz', 9912422, 'bytes.')\n",
      "('Extracting', 'MNIST_data/train-images-idx3-ubyte.gz')\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "only integer scalar arrays can be converted to a scalar index",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-5946a4cc444d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;31m# load MNIST data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m \u001b[0mmnist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_data_sets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"MNIST_data/\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mone_hot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m \u001b[0mtrX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mteX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mteY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmnist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmnist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmnist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmnist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/shelter/Documents/huxiaoman7/learningdl/Chapter5/input_data.py\u001b[0m in \u001b[0;36mread_data_sets\u001b[0;34m(train_dir, fake_data, one_hot)\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[0mVALIDATION_SIZE\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m5000\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m     \u001b[0mlocal_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmaybe_download\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTRAIN_IMAGES\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dir\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m#下载训练集的图像,返回图像文件所在目录\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m     \u001b[0mtrain_images\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocal_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m     \u001b[0mlocal_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmaybe_download\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTRAIN_LABELS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dir\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m#下载训练集的label\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m     \u001b[0mtrain_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocal_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mone_hot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mone_hot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/shelter/Documents/huxiaoman7/learningdl/Chapter5/input_data.py\u001b[0m in \u001b[0;36mextract_images\u001b[0;34m(filename)\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0mrows\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_read32\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbytestream\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0mcols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_read32\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbytestream\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m         \u001b[0mbuf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbytestream\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrows\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mcols\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnum_images\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrombuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muint8\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m#将buf转化为1维数组\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrows\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcols\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m#改变数组形状:(60000, 28, 28, 1)for train, (10000, 28, 28, 1)for test\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/shelter/anaconda/lib/python2.7/gzip.pyc\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, size)\u001b[0m\n\u001b[1;32m    273\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m         \u001b[0moffset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moffset\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextrastart\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 275\u001b[0;31m         \u001b[0mchunk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextrabuf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0moffset\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0moffset\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    276\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextrasize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextrasize\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    277\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: only integer scalar arrays can be converted to a scalar index"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import input_data\n",
    "\n",
    "mnist_width = 28\n",
    "n_visible = mnist_width * mnist_width\n",
    "n_hidden = 500\n",
    "corruption_level = 0.3\n",
    "\n",
    "# 输入的一张图片用28x28=784的向量表示.\n",
    "X = tf.placeholder(\"float\", [None, n_visible], name='X')\n",
    "\n",
    "# 用于将部分输入数据置为0\n",
    "mask = tf.placeholder(\"float\", [None, n_visible], name='mask')\n",
    "\n",
    "# create nodes for hidden variables\n",
    "W_init_max = 4 * np.sqrt(6. / (n_visible + n_hidden))\n",
    "W_init = tf.random_uniform(shape=[n_visible, n_hidden],\n",
    "                           minval=-W_init_max,\n",
    "                           maxval=W_init_max)\n",
    "# 编码器\n",
    "W = tf.Variable(W_init, name='W')#shape:784x500\n",
    "b = tf.Variable(tf.zeros([n_hidden]), name='b')#隐含层的偏置\n",
    "#解码器\n",
    "W_prime = tf.transpose(W)  \n",
    "b_prime = tf.Variable(tf.zeros([n_visible]), name='b_prime')\n",
    "\n",
    "\n",
    "def model(X, mask, W, b, W_prime, b_prime):\n",
    "    tilde_X = mask * X  # corrupted X\n",
    "\n",
    "    Y = tf.nn.sigmoid(tf.matmul(tilde_X, W) + b)  # hidden state\n",
    "    Z = tf.nn.sigmoid(tf.matmul(Y, W_prime) + b_prime)  # reconstructed input\n",
    "    return Z\n",
    "\n",
    "# build model graph\n",
    "Z = model(X, mask, W, b, W_prime, b_prime)\n",
    "\n",
    "# create cost function\n",
    "cost = tf.reduce_sum(tf.pow(X - Z, 2))  # minimize squared error\n",
    "train_op = tf.train.GradientDescentOptimizer(0.02).minimize(cost)  # construct an optimizer\n",
    "\n",
    "# load MNIST data\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\n",
    "trX, trY, teX, teY = mnist.train.images, mnist.train.labels, mnist.test.images, mnist.test.labels\n",
    "\n",
    "# Launch the graph in a session\n",
    "with tf.Session() as sess:\n",
    "    # you need to initialize all variables\n",
    "    tf.initialize_all_variables().run()\n",
    "\n",
    "    for i in range(100):\n",
    "        for start, end in zip(range(0, len(trX), 128), range(128, len(trX)+1, 128)):\n",
    "            input_ = trX[start:end]\n",
    "            mask_np = np.random.binomial(1, 1 - corruption_level, input_.shape)\n",
    "            sess.run(train_op, feed_dict={X: input_, mask: mask_np})\n",
    "\n",
    "        mask_np = np.random.binomial(1, 1 - corruption_level, teX.shape)\n",
    "        print(i, sess.run(cost, feed_dict={X: teX, mask: mask_np}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
