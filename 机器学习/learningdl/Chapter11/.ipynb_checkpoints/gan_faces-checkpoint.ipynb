{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 用DCGAN生成二次元萌妹子头像"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 训练数据处理\n",
    "- 数据源：[百度云盘](https://pan.baidu.com/s/1eSifHcA) 提取码：g5qa\n",
    "- 创建一个生成器\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## 创建一个数据生成器\n",
    "class Avatar:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.data_name = 'faces'\n",
    "        self.source_shape = (96, 96, 3)\n",
    "        self.resize_shape = (48, 48, 3)\n",
    "        self.crop = True\n",
    "        self.img_shape = self.source_shape if not self.crop else self.resize_shape\n",
    "        self.img_list = self._get_img_list()\n",
    "        self.batch_size = 64\n",
    "        self.batch_shape = (self.batch_size, ) + self.img_shape\n",
    "        self.chunk_size = len(self.img_list) // self.batch_size\n",
    "\n",
    "    def _get_img_list(self):\n",
    "        path = os.path.join(os.getcwd(), self.data_name, '*.jpg')\n",
    "        return glob(path)\n",
    "\n",
    "    def _get_img(self, name):\n",
    "        assert name in self.img_list\n",
    "        img = scipy.misc.imread(name).astype(np.float32)\n",
    "        assert img.shape == self.source_shape\n",
    "        return self._resize(img) if self.crop else img\n",
    "\n",
    "    def _resize(self, img):\n",
    "        h, w = img.shape[:2]\n",
    "        resize_h, resize_w = self.resize_shape[:2]\n",
    "        crop_h, crop_w = self.source_shape[:2]\n",
    "        j = int(round((h - crop_h) / 2.))\n",
    "        i = int(round((w - crop_w) / 2.))\n",
    "        cropped_image = scipy.misc.imresize(img[j:j + crop_h, i:i + crop_w], [resize_h, resize_w])\n",
    "        return np.array(cropped_image) / 127.5 - 1.\n",
    "\n",
    "    @staticmethod\n",
    "    def save_img(image, path):\n",
    "        scipy.misc.imsave(path, image)\n",
    "        return True\n",
    "\n",
    "    def batches(self):\n",
    "        start = 0\n",
    "        end = self.batch_size\n",
    "        for _ in range(self.chunk_size):\n",
    "            name_list = self.img_list[start:end]\n",
    "            imgs = [self._get_img(name) for name in name_list]\n",
    "            batches = np.zeros(self.batch_shape)\n",
    "            batches[::] = imgs\n",
    "            yield batches\n",
    "            start += self.batch_size\n",
    "            end += self.batch_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型参数定义"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def __init__(self):  \n",
    "    self.avatar = Avatar()  \n",
    "    # 真实图片shape (height, width, depth)  \n",
    "    self.img_shape = self.avatar.img_shape  \n",
    "    # 一个batch的图片向量shape (batch, height, width, depth)  \n",
    "    self.batch_shape = self.avatar.batch_shape  \n",
    "    # 一个batch包含图片数量  \n",
    "    self.batch_size = self.avatar.batch_size  \n",
    "    # batch数量  \n",
    "    self.chunk_size = self.avatar.chunk_size  \n",
    "  \n",
    "    # 噪音图片size  \n",
    "    self.noise_img_size = 100  \n",
    "    # 卷积转置输出通道数量  \n",
    "    self.gf_size = 64  \n",
    "    # 卷积输出通道数量  \n",
    "    self.df_size = 64  \n",
    "    # 训练循环次数  \n",
    "    self.epoch_size = 50  \n",
    "    # 学习率  \n",
    "    self.learning_rate = 0.0002  \n",
    "    # 优化指数衰减率  \n",
    "    self.beta1 = 0.5  \n",
    "    # 生成图片数量  \n",
    "    self.sample_size = 64  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 输入数据定义"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 真实图片  \n",
    "real_imgs = tf.placeholder(tf.float32, self.batch_shape, name='real_images')  \n",
    "# 噪声图片  \n",
    "noise_imgs = tf.placeholder(tf.float32, [None, self.noise_img_size], name='noise_images') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 定义Generator\n",
    "- DCGAN的生成器为卷积网络，使用转置卷积进行上采样，去除pooling层，利用batch normalization加快收敛速度。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generator(self, noise_imgs, train=True):  \n",
    "    with tf.variable_scope('generator'):  \n",
    "        # 分别对应每个layer的height, width  \n",
    "        s_h, s_w, _ = self.img_shape  \n",
    "        s_h2, s_w2 = self.conv_out_size_same(s_h, 2), self.conv_out_size_same(s_w, 2)  \n",
    "        s_h4, s_w4 = self.conv_out_size_same(s_h2, 2), self.conv_out_size_same(s_w2, 2)  \n",
    "        s_h8, s_w8 = self.conv_out_size_same(s_h4, 2), self.conv_out_size_same(s_w4, 2)  \n",
    "        s_h16, s_w16 = self.conv_out_size_same(s_h8, 2), self.conv_out_size_same(s_w8, 2)  \n",
    "  \n",
    "        # layer 0  \n",
    "        # 对输入噪音图片进行线性变换  \n",
    "        z, h0_w, h0_b = self.linear(noise_imgs, self.gf_size*8*s_h16*s_w16)  \n",
    "        # reshape为合适的输入层格式  \n",
    "        h0 = tf.reshape(z, [-1, s_h16, s_w16, self.gf_size * 8])  \n",
    "        # 对数据进行归一化处理 加快收敛速度  \n",
    "        h0 = self.batch_normalizer(h0, train=train, name='g_bn0')  \n",
    "        # 激活函数  \n",
    "        h0 = tf.nn.relu(h0)  \n",
    "  \n",
    "        # layer 1  \n",
    "        # 卷积转置进行上采样  \n",
    "        h1, h1_w, h1_b = self.deconv2d(h0, [self.batch_size, s_h8, s_w8, self.gf_size*4], name='g_h1')  \n",
    "        h1 = self.batch_normalizer(h1, train=train, name='g_bn1')  \n",
    "        h1 = tf.nn.relu(h1)  \n",
    "  \n",
    "        # layer 2  \n",
    "        h2, h2_w, h2_b = self.deconv2d(h1, [self.batch_size, s_h4, s_w4, self.gf_size*2], name='g_h2')  \n",
    "        h2 = self.batch_normalizer(h2, train=train, name='g_bn2')  \n",
    "        h2 = tf.nn.relu(h2)  \n",
    "  \n",
    "        # layer 3  \n",
    "        h3, h3_w, h3_b = self.deconv2d(h2, [self.batch_size, s_h2, s_w2, self.gf_size*1], name='g_h3')  \n",
    "        h3 = self.batch_normalizer(h3, train=train, name='g_bn3')  \n",
    "        h3 = tf.nn.relu(h3)  \n",
    "  \n",
    "        # layer 4  \n",
    "        h4, h4_w, h4_b = self.deconv2d(h3, self.batch_shape, name='g_h4')  \n",
    "        return tf.nn.tanh(h4) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 生成Discriminator判别器\n",
    "- DCGAN的判别器为卷积网络，这里使用卷积操作对图像进行特征提取识别。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def discriminator(self, real_imgs, reuse=False):  \n",
    "    with tf.variable_scope(\"discriminator\", reuse=reuse):  \n",
    "        # layer 0  \n",
    "        # 卷积操作  \n",
    "        h0 = self.conv2d(real_imgs, self.df_size, name='d_h0_conv')  \n",
    "        # 激活函数  \n",
    "        h0 = self.lrelu(h0)  \n",
    "  \n",
    "        # layer 1  \n",
    "        h1 = self.conv2d(h0, self.df_size*2, name='d_h1_conv')  \n",
    "        h1 = self.batch_normalizer(h1, name='d_bn1')  \n",
    "        h1 = self.lrelu(h1)  \n",
    "  \n",
    "        # layer 2  \n",
    "        h2 = self.conv2d(h1, self.df_size*4, name='d_h2_conv')  \n",
    "        h2 = self.batch_normalizer(h2, name='d_bn2')  \n",
    "        h2 = self.lrelu(h2)  \n",
    "  \n",
    "        # layer 3  \n",
    "        h3 = self.conv2d(h2, self.df_size*8, name='d_h3_conv')  \n",
    "        h3 = self.batch_normalizer(h3, name='d_bn3')  \n",
    "        h3 = self.lrelu(h3)  \n",
    "  \n",
    "        # layer 4  \n",
    "        h4, _, _ = self.linear(tf.reshape(h3, [self.batch_size, -1]), 1, name='d_h4_lin')  \n",
    "  \n",
    "        return tf.nn.sigmoid(h4), h4 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 定义损失函数和优化器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "@staticmethod  \n",
    "def loss_graph(real_logits, fake_logits):  \n",
    "    # 生成器图片loss  \n",
    "    # 生成器希望判别器判断出来的标签为1  \n",
    "    gen_loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=fake_logits, labels=tf.ones_like(fake_logits)))  \n",
    "    # 判别器识别生成器图片loss  \n",
    "    # 判别器希望识别出来的标签为0  \n",
    "    fake_loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=fake_logits, labels=tf.zeros_like(fake_logits)))  \n",
    "    # 判别器识别真实图片loss  \n",
    "    # 判别器希望识别出来的标签为1  \n",
    "    real_loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=real_logits, labels=tf.ones_like(real_logits)))  \n",
    "    # 判别器总loss  \n",
    "    dis_loss = tf.add(fake_loss, real_loss)  \n",
    "    return gen_loss, fake_loss, real_loss, dis_loss  \n",
    " \n",
    "@staticmethod  \n",
    "def optimizer_graph(gen_loss, dis_loss, learning_rate, beta1):  \n",
    "    # 所有定义变量  \n",
    "    train_vars = tf.trainable_variables()  \n",
    "    # 生成器变量  \n",
    "    gen_vars = [var for var in train_vars if var.name.startswith('generator')]  \n",
    "    # 判别器变量  \n",
    "    dis_vars = [var for var in train_vars if var.name.startswith('discriminator')]  \n",
    "    # optimizer  \n",
    "    # 生成器与判别器作为两个网络需要分别优化  \n",
    "    gen_optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate, beta1=beta1).minimize(gen_loss, var_list=gen_vars)  \n",
    "    dis_optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate, beta1=beta1).minimize(dis_loss, var_list=dis_vars)  \n",
    "    return gen_optimizer, dis_optimizer "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 开始训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 开始训练  \n",
    "saver = tf.train.Saver()  \n",
    "step = 0  \n",
    "# 指定占用GPU比例  \n",
    "# tensorflow默认占用全部GPU显存 防止在机器显存被其他程序占用过多时可能在启动时报错  \n",
    "gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=0.8)  \n",
    "with tf.Session(config=tf.ConfigProto(gpu_options=gpu_options)) as sess:  \n",
    "    sess.run(tf.global_variables_initializer())  \n",
    "    for epoch in range(self.epoch_size):  \n",
    "        batches = self.avatar.batches()  \n",
    "        for batch_imgs in batches:  \n",
    "            # generator的输入噪声  \n",
    "            noises = np.random.uniform(-1, 1, size=(self.batch_size, self.noise_img_size)).astype(np.float32)  \n",
    "            # 优化  \n",
    "            _ = sess.run(dis_optimizer, feed_dict={real_imgs: batch_imgs, noise_imgs: noises})  \n",
    "            _ = sess.run(gen_optimizer, feed_dict={noise_imgs: noises})  \n",
    "            _ = sess.run(gen_optimizer, feed_dict={noise_imgs: noises})  \n",
    "            step += 1  \n",
    "            print(datetime.now().strftime('%c'), epoch, step) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## 见图片"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
