{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SSD的Tensorflow实现"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 定义ssd的网络参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "self.ssd_params = SSDParams(img_shape=(300, 300),   # 输入图片大小\n",
    "        num_classes=21,     # 类别数+背景\n",
    "        no_annotation_label=21,\n",
    "        feat_layers=[\"block4\", \"block7\", \"block8\", \"block9\", \"block10\", \"block11\"],   # 要进行检测的特征图name\n",
    "        feat_shapes=[(38, 38), (19, 19), (10, 10), (5, 5), (3, 3), (1, 1)],  # 特征图大小\n",
    "        anchor_size_bounds=[0.15, 0.90],  # 特征图尺度范围\n",
    "        anchor_sizes=[(21., 45.),\n",
    "          (45., 99.),\n",
    "          (99., 153.),\n",
    "          (153., 207.),\n",
    "          (207., 261.),\n",
    "          (261., 315.)],  # 不同特征图的先验框尺度（第一个值是s_k，第2个值是s_k+1）\n",
    "        anchor_ratios=[[2, .5],\n",
    "           [2, .5, 3, 1. / 3],\n",
    "           [2, .5, 3, 1. / 3],\n",
    "           [2, .5, 3, 1. / 3],\n",
    "           [2, .5],\n",
    "           [2, .5]], # 特征图先验框所采用的长宽比（每个特征图都有2个正方形先验框）\n",
    "        anchor_steps=[8, 16, 32, 64, 100, 300],  # 特征图的单元大小\n",
    "        anchor_offset=0.5,                 # 偏移值，确定先验框中心\n",
    "        normalizations=[20, -1, -1, -1, -1, -1],  # l2 norm\n",
    "        prior_scaling=[0.1, 0.1, 0.2, 0.2]       # variance\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 构建网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def _built_net(self):\n",
    "        \"\"\"Construct the SSD net\"\"\"\n",
    "        self.end_points = {}  # record the detection layers output\n",
    "        self._images = tf.placeholder(tf.float32, shape=[None, self.ssd_params.img_shape[0],\n",
    "                                                        self.ssd_params.img_shape[1], 3])\n",
    "        with tf.variable_scope(\"ssd_300_vgg\"):\n",
    "            # original vgg layers\n",
    "            # block 1\n",
    "            net = conv2d(self._images, 64, 3, scope=\"conv1_1\")\n",
    "            net = conv2d(net, 64, 3, scope=\"conv1_2\")\n",
    "            self.end_points[\"block1\"] = net\n",
    "            net = max_pool2d(net, 2, scope=\"pool1\")\n",
    "            # block 2\n",
    "            net = conv2d(net, 128, 3, scope=\"conv2_1\")\n",
    "            net = conv2d(net, 128, 3, scope=\"conv2_2\")\n",
    "            self.end_points[\"block2\"] = net\n",
    "            net = max_pool2d(net, 2, scope=\"pool2\")\n",
    "            # block 3\n",
    "            net = conv2d(net, 256, 3, scope=\"conv3_1\")\n",
    "            net = conv2d(net, 256, 3, scope=\"conv3_2\")\n",
    "            net = conv2d(net, 256, 3, scope=\"conv3_3\")\n",
    "            self.end_points[\"block3\"] = net\n",
    "            net = max_pool2d(net, 2, scope=\"pool3\")\n",
    "            # block 4\n",
    "            net = conv2d(net, 512, 3, scope=\"conv4_1\")\n",
    "            net = conv2d(net, 512, 3, scope=\"conv4_2\")\n",
    "            net = conv2d(net, 512, 3, scope=\"conv4_3\")\n",
    "            self.end_points[\"block4\"] = net\n",
    "            net = max_pool2d(net, 2, scope=\"pool4\")\n",
    "            # block 5\n",
    "            net = conv2d(net, 512, 3, scope=\"conv5_1\")\n",
    "            net = conv2d(net, 512, 3, scope=\"conv5_2\")\n",
    "            net = conv2d(net, 512, 3, scope=\"conv5_3\")\n",
    "            self.end_points[\"block5\"] = net\n",
    "            print(net)\n",
    "            net = max_pool2d(net, 3, stride=1, scope=\"pool5\")\n",
    "            print(net)\n",
    "\n",
    "            # additional SSD layers\n",
    "            # block 6: use dilate conv\n",
    "            net = conv2d(net, 1024, 3, dilation_rate=6, scope=\"conv6\")\n",
    "            self.end_points[\"block6\"] = net\n",
    "            #net = dropout(net, is_training=self.is_training)\n",
    "            # block 7\n",
    "            net = conv2d(net, 1024, 1, scope=\"conv7\")\n",
    "            self.end_points[\"block7\"] = net\n",
    "            # block 8\n",
    "            net = conv2d(net, 256, 1, scope=\"conv8_1x1\")\n",
    "            net = conv2d(pad2d(net, 1), 512, 3, stride=2, scope=\"conv8_3x3\",\n",
    "                         padding=\"valid\")\n",
    "            self.end_points[\"block8\"] = net\n",
    "            # block 9\n",
    "            net = conv2d(net, 128, 1, scope=\"conv9_1x1\")\n",
    "            net = conv2d(pad2d(net, 1), 256, 3, stride=2, scope=\"conv9_3x3\",\n",
    "                         padding=\"valid\")\n",
    "            self.end_points[\"block9\"] = net\n",
    "            # block 10\n",
    "            net = conv2d(net, 128, 1, scope=\"conv10_1x1\")\n",
    "            net = conv2d(net, 256, 3, scope=\"conv10_3x3\", padding=\"valid\")\n",
    "            self.end_points[\"block10\"] = net\n",
    "            # block 11\n",
    "            net = conv2d(net, 128, 1, scope=\"conv11_1x1\")\n",
    "            net = conv2d(net, 256, 3, scope=\"conv11_3x3\", padding=\"valid\")\n",
    "            self.end_points[\"block11\"] = net\n",
    "\n",
    "            # class and location predictions\n",
    "            predictions = []\n",
    "            logits = []\n",
    "            locations = []\n",
    "            for i, layer in enumerate(self.ssd_params.feat_layers):\n",
    "                cls, loc = ssd_multibox_layer(self.end_points[layer], self.ssd_params.num_classes,\n",
    "                                              self.ssd_params.anchor_sizes[i],\n",
    "                                              self.ssd_params.anchor_ratios[i],\n",
    "                                              self.ssd_params.normalizations[i], scope=layer+\"_box\")\n",
    "                predictions.append(tf.nn.softmax(cls))\n",
    "                logits.append(cls)\n",
    "                locations.append(loc)\n",
    "            return predictions, logits, locations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 定义检测图"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 获取类别和位置的预测值\n",
    "def ssd_multibox_layer(x, num_classes, sizes, ratios, normalization=-1, scope=\"multibox\"):\n",
    "        pre_shape = x.get_shape().as_list()[1:-1]\n",
    "        pre_shape = [-1] + pre_shape\n",
    "        with tf.variable_scope(scope):\n",
    "            # l2 norm\n",
    "            if normalization > 0:\n",
    "                x = l2norm(x, normalization)\n",
    "                print(x)\n",
    "            # numbers of anchors\n",
    "            n_anchors = len(sizes) + len(ratios)\n",
    "            # location predictions\n",
    "            loc_pred = conv2d(x, n_anchors*4, 3, activation=None, scope=\"conv_loc\")\n",
    "            loc_pred = tf.reshape(loc_pred, pre_shape + [n_anchors, 4])\n",
    "            # class prediction\n",
    "            cls_pred = conv2d(x, n_anchors*num_classes, 3, activation=None, scope=\"conv_cls\")\n",
    "            cls_pred = tf.reshape(cls_pred, pre_shape + [n_anchors, num_classes])\n",
    "            return cls_pred, loc_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 将得到过滤得到的边界框，其中classes, scores, bboxes分别表示类别，置信度值以及边界框位置\n",
    "classes, scores, bboxes = self._bboxes_select(predictions, locations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 对ssd进行测试，得先提前下载好训练好的权重文件\n",
    "ssd_net = SSD()\n",
    "classes, scores, bboxes = ssd_net.detections()\n",
    "images = ssd_net.images()\n",
    "\n",
    "sess = tf.Session()\n",
    "# Restore SSD model.\n",
    "ckpt_filename = './ssd_checkpoints/ssd_vgg_300_weights.ckpt'\n",
    "sess.run(tf.global_variables_initializer())\n",
    "saver = tf.train.Saver()\n",
    "saver.restore(sess, ckpt_filename)\n",
    "\n",
    "img = cv2.imread('./demo/dog.jpg')\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "img_prepocessed = preprocess_image(img)   # 预处理图片，主要是归一化和resize\n",
    "rclasses, rscores, rbboxes = sess.run([classes, scores, bboxes],\n",
    "                                      feed_dict={images: img_prepocessed})\n",
    "rclasses, rscores, rbboxes = process_bboxes(rclasses, rscores, rbboxes)  # 处理预测框，包括clip,sort,nms\n",
    "\n",
    "plt_bboxes(img, rclasses, rscores, rbboxes)  # 绘制检测结果"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
